{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report,classification\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pickled data\n",
    "tweets = pd.read_pickle(\"../data/combined_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.696524\n",
       "0    0.303476\n",
       "Name: informative, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline accuracy\n",
    "tweets.informative.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name variables \n",
    "\n",
    "X = tweets[[\"tweet_text\"]]\n",
    "y = tweets[\"informative\"]\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords from NLTK and add custom words\n",
    "mystopwords = stopwords.words('english')\n",
    "mystopwords.extend(['hurricane','tornado','harvey','irma','joplin','sandy','maria',\n",
    "                    'like','would','get','x200b','https','one','www','com','org','etc','could'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model with Count Vectorizer\n",
      "Train data accuracy: 0.988\n",
      "Test data accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Bernouilli with CVEC\n",
    "cvec = CountVectorizer(stop_words=None,max_features=None,max_df=1.0,min_df=1, ngram_range=(1,1))\n",
    "\n",
    "# Fit our CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['tweet_text']).todense(),\n",
    "                            columns = cvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['tweet_text']).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# instantiate and fit model \n",
    "nb = BernoulliNB(alpha=.01)\n",
    "nb.fit(X_train_cvec, y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Naive Bayes model with Count Vectorizer')\n",
    "print(f'Train data accuracy: {nb.score(X_train_cvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {nb.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model with TF-IDF Vectorizer\n",
      "Train data accuracy: 0.838\n",
      "Test data accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Bernouilli with Tfidf\n",
    "tvec = TfidfVectorizer(stop_words=None,max_features=3000,max_df=1.0,min_df=1, ngram_range=(1,1))\n",
    "\n",
    "# Fit our CountVectorizer on the training data and transform training data.\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train['tweet_text']).todense(),\n",
    "                            columns = tvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test['tweet_text']).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# instantiate and fit model \n",
    "nb = BernoulliNB(alpha=.1)\n",
    "nb.fit(X_train_tvec, y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Naive Bayes model with TF-IDF Vectorizer')\n",
    "print(f'Train data accuracy: {nb.score(X_train_tvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {nb.score(X_test_tvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine model with Count Vectorizer\n",
      "Train data accuracy: 0.845\n",
      "Test data accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "# SVM model with CVEC\n",
    "cvec = CountVectorizer(stop_words=mystopwords,max_features=800, ngram_range=(1,1))\n",
    "\n",
    "# Fit  CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['tweet_text']).todense(),\n",
    "                            columns = cvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['tweet_text']).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "# Instantiate SVM.\n",
    "# svc = svm.SVC(kernel='poly', C = 1.8, gamma = .05) \n",
    "svc = svm.SVC(kernel='rbf', C = 15, gamma = .02)  \n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(X_train_cvec,y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Support Vector Machine model with Count Vectorizer')\n",
    "print(f'Train data accuracy: {svc.score(X_train_cvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {svc.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model with Count Vectorizer and TweetTokenzer\n",
      "Train data accuracy: 0.978\n",
      "Test data accuracy: 0.821\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer \n",
    "tknzr = TweetTokenizer()\n",
    "cvec = CountVectorizer(stop_words=\"english\", tokenizer=tknzr.tokenize)\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['tweet_text']).todense(), columns = cvec.get_feature_names())\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['tweet_text']).todense(), columns = cvec.get_feature_names())\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(X_train_cvec, y_train)\n",
    "# Score model on the training set.\n",
    "print('Logistic Regression model with Count Vectorizer and TweetTokenzer')\n",
    "print(f'Train data accuracy: {lr.score(X_train_cvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {lr.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict neg</th>\n",
       "      <th>predict pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>804</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>280</td>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predict neg  predict pos\n",
       "actual neg          804          479\n",
       "actual pos          280         2666"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "y_pred = lr.predict(X_test_cvec)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, columns=['predict neg', 'predict pos'], index=['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list false positives - predicted Science but actually History\n",
    "mask = (X_test['y_test']==0) & (X_test['y_pred'] ==1)\n",
    "print('Predicted Science but actually History')\n",
    "for i in X_test[mask].index:\n",
    "    print(f'Row {i}: {X_test.text.loc[i]}')\n",
    "    print('-------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
