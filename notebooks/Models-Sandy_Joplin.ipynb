{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models of disaster tweet categories using Sandy-Joplin training data\n",
    "  -- Several model types tested\n",
    "  \n",
    "  \n",
    "  -- Use best model to predict categories for Hurricane Michael tweets (out-of-event sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauls\\Anaconda3\\envs\\dsi\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report,classification\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pickled dataframe of Sandy-Joplin Tweets\n",
    "tweets = pd.read_pickle(\"../data/train3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.430952\n",
       "2.0    0.185838\n",
       "4.0    0.112784\n",
       "1.0    0.098366\n",
       "3.0    0.081705\n",
       "5.0    0.075617\n",
       "6.0    0.014739\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline accuracy\n",
    "tweets.y.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3121 entries, 204690718 to 223607572\n",
      "Data columns (total 20 columns):\n",
      "_golden                  3121 non-null bool\n",
      "_last_judgment_at        3121 non-null object\n",
      "_trusted_judgments       3121 non-null int64\n",
      "_unit_state              3121 non-null object\n",
      "category                 1776 non-null object\n",
      "choose_one               1345 non-null object\n",
      "choose_one:confidence    3121 non-null float64\n",
      "choose_one_gold          151 non-null object\n",
      "event                    1000 non-null object\n",
      "id                       1233 non-null float64\n",
      "nil                      1 non-null object\n",
      "predicted                887 non-null object\n",
      "retweetcount             649 non-null float64\n",
      "screenname               1221 non-null object\n",
      "text_no_rt               1888 non-null object\n",
      "tweet                    3121 non-null object\n",
      "type                     543 non-null object\n",
      "user                     1000 non-null object\n",
      "userid                   1221 non-null float64\n",
      "y                        3121 non-null float64\n",
      "dtypes: bool(1), float64(5), int64(1), object(13)\n",
      "memory usage: 490.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(col):\n",
    "    # convert text to lower case\n",
    "    col = col.str.lower()\n",
    "\n",
    "    # remove URLs\n",
    "    col = col.apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "    col = col.apply(lambda x: re.split('http:\\/\\/.*', str(x))[0])\n",
    "    col = col.replace(r'www\\S+', '', regex=True)\n",
    "\n",
    "    #remove \"RT\" string\n",
    "    col = col.map(lambda x: x.lstrip('rt'))\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweet text\n",
    "tweets['clean_text'] = clean_tweets(tweets['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name variables \n",
    "X = tweets[[\"clean_text\"]]\n",
    "y = tweets[\"y\"]\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords from NLTK and add custom words\n",
    "mystopwords = stopwords.words('english')\n",
    "mystopwords.extend(['hurricane','tornado','harvey','irma','joplin','sandy','maria',\n",
    "                    'like','would','get','x200b','https','one','www','com','org','etc','could'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model with Count Vectorizer\n",
      "Train data accuracy: 0.824\n",
      "Test data accuracy: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes with CVEC\n",
    "tknzr = TweetTokenizer()\n",
    "cvec = CountVectorizer(tokenizer=tknzr.tokenize,stop_words=None,\n",
    "                       max_features=3000,max_df=1.0,min_df=2, \n",
    "                       ngram_range=(1,1))\n",
    "\n",
    "# Fit  CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['clean_text']).todense(),\n",
    "                            columns = cvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['clean_text']).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# instantiate and fit model \n",
    "nb = MultinomialNB(alpha=1)\n",
    "nb.fit(X_train_cvec, y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Naive Bayes model with Count Vectorizer')\n",
    "print(f'Train data accuracy: {nb.score(X_train_cvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {nb.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model with TF-IDF Vectorizer\n",
      "Train data accuracy: 0.693\n",
      "Test data accuracy: 0.634\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes with Tfidf\n",
    "tvec = TfidfVectorizer(tokenizer=tknzr.tokenize,stop_words=None,\n",
    "                       max_features=1000,max_df=1.0,min_df=4, ngram_range=(1,2))\n",
    "\n",
    "# Fit Vectorizer on the training data and transform training data.\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train['clean_text']).todense(),\n",
    "                            columns = tvec.get_feature_names())\n",
    "# Transform testing data with the already-fit Vectorizer.\n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test['clean_text']).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# instantiate and fit model \n",
    "nb = MultinomialNB(alpha=1)\n",
    "nb.fit(X_train_tvec, y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Naive Bayes model with TF-IDF Vectorizer')\n",
    "print(f'Train data accuracy: {nb.score(X_train_tvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {nb.score(X_test_tvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine model with Count Vectorizer\n",
      "Train data accuracy: 0.845\n",
      "Test data accuracy: 0.609\n"
     ]
    }
   ],
   "source": [
    "# SVM model with CVEC\n",
    "cvec = CountVectorizer(stop_words=mystopwords,max_features=800, ngram_range=(1,1))\n",
    "\n",
    "# Fit  CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['clean_text']).todense(),\n",
    "                            columns = cvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['clean_text']).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "# Instantiate SVM.\n",
    "# svc = svm.SVC(kernel='poly', C = 1.8, gamma = .05) \n",
    "svc = svm.SVC(kernel='rbf', C = 1, gamma = .2)  \n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(X_train_cvec,y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Support Vector Machine model with Count Vectorizer')\n",
    "print(f'Train data accuracy: {svc.score(X_train_cvec,y_train):.3f}')\n",
    "\n",
    "# Score model on the testing set.\n",
    "print(f'Test data accuracy: {svc.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine model with TFIDF Vectorizer\n",
      "Train data accuracy: 0.673\n",
      "Test data accuracy: 0.629\n"
     ]
    }
   ],
   "source": [
    "# SVM model with TVEC\n",
    "tvec = TfidfVectorizer(tokenizer=tknzr.tokenize,stop_words=mystopwords,\n",
    "                       max_features=800,max_df=1.0,min_df=4, ngram_range=(1,1))\n",
    "\n",
    "# Fit Vectorizer on the training data and transform training data.\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train['clean_text']).todense(),\n",
    "                            columns = tvec.get_feature_names())\n",
    "# Transform testing data with the already-fit Vectorizer.\n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test['clean_text']).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "# Instantiate SVM.\n",
    "# svc = svm.SVC(kernel='poly', C = 1.8, gamma = .05) \n",
    "svc = svm.SVC(kernel='rbf', C = 1, gamma = .2)  \n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(X_train_tvec,y_train)\n",
    "\n",
    "# Score model on the training set.\n",
    "print('Support Vector Machine model with TFIDF Vectorizer')\n",
    "print(f'Train data accuracy: {svc.score(X_train_tvec,y_train):.3f}')\n",
    "\n",
    "# Score model on the testing set.\n",
    "print(f'Test data accuracy: {svc.score(X_test_tvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model with TFIDF Vectorizer and TweetTokenzer\n",
      "Train data accuracy: 0.842\n",
      "Test data accuracy: 0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauls\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with TFIDF Vectorizer \n",
    "tknzr = TweetTokenizer()\n",
    "tvec = TfidfVectorizer(tokenizer=tknzr.tokenize,stop_words=mystopwords,\n",
    "                       max_features=None,max_df=1.0,min_df=2, ngram_range=(1,1))\n",
    "\n",
    "# Fit Vectorizer on the training data and transform training data.\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train['clean_text']).todense(),\n",
    "                            columns = tvec.get_feature_names())\n",
    "# Transform testing data with the already-fit Vectorizer.\n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test['clean_text']).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "# fit model\n",
    "lr = LogisticRegression(penalty='l2',C=2,random_state=42,solver='liblinear')\n",
    "lr_model = lr.fit(X_train_tvec, y_train)\n",
    "# Score model on the training set.\n",
    "print('Logistic Regression model with TFIDF Vectorizer and TweetTokenzer')\n",
    "print(f'Train data accuracy: {lr.score(X_train_tvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {lr.score(X_test_tvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauls\\Anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model with Count Vectorizer and TweetTokenzer\n",
      "Train data accuracy: 0.881\n",
      "Test data accuracy: 0.676\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with CountVectorizer \n",
    "tknzr = TweetTokenizer()\n",
    "cvec = CountVectorizer(stop_words=mystopwords, tokenizer=tknzr.tokenize)\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['clean_text']).todense(), columns = cvec.get_feature_names())\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['clean_text']).todense(), columns = cvec.get_feature_names())\n",
    "\n",
    "# fit model\n",
    "lr = LogisticRegression(penalty='l2',C=.3,random_state=42,solver='liblinear')\n",
    "lr_model = lr.fit(X_train_cvec, y_train)\n",
    "# Score model on the training set.\n",
    "print('Logistic Regression model with Count Vectorizer and TweetTokenzer')\n",
    "print(f'Train data accuracy: {lr.score(X_train_cvec,y_train):.3f}')\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(f'Test data accuracy: {lr.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 0.508\n",
      "Testing accuracy is: 0.502\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "model = RandomForestClassifier(max_depth=20,random_state=42,min_samples_leaf=5,n_estimators=10)\n",
    "model.fit(X_train_cvec,y_train)\n",
    "y_pred = model.predict(X_test_cvec)\n",
    "y_pred_train = model.predict(X_train_cvec)\n",
    "\n",
    "print(f'Training accuracy is: {model.score(X_train_cvec,y_train):.3f}')\n",
    "print(f'Testing accuracy is: {model.score(X_test_cvec,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uninformative</th>\n",
       "      <td>0.913947</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>0.020772</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Casualties and damage</th>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caution and advice</th>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informative, other</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Source</th>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.079545</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donations of money, goods or services</th>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People missing, found or seen</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0         1         2         3  \\\n",
       "uninformative                          0.913947  0.005935  0.041543  0.005935   \n",
       "Casualties and damage                  0.311688  0.545455  0.090909  0.012987   \n",
       "Caution and advice                     0.275862  0.006897  0.682759  0.013793   \n",
       "Informative, other                     0.656250  0.031250  0.062500  0.125000   \n",
       "Information Source                     0.329545  0.079545  0.056818  0.068182   \n",
       "Donations of money, goods or services  0.338983  0.067797  0.016949  0.000000   \n",
       "People missing, found or seen          0.000000  0.090909  0.000000  0.000000   \n",
       "\n",
       "                                              4         5         6  \n",
       "uninformative                          0.011869  0.020772  0.000000  \n",
       "Casualties and damage                  0.038961  0.000000  0.000000  \n",
       "Caution and advice                     0.013793  0.006897  0.000000  \n",
       "Informative, other                     0.109375  0.015625  0.000000  \n",
       "Information Source                     0.431818  0.034091  0.000000  \n",
       "Donations of money, goods or services  0.084746  0.491525  0.000000  \n",
       "People missing, found or seen          0.363636  0.181818  0.363636  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# source: https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class\n",
    "y_pred = lr.predict(X_test_cvec)\n",
    "\n",
    "#Get the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# normalize the diagonal entries\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#The diagonal entries are the accuracies of each class\n",
    "cm.diagonal()\n",
    "\n",
    "categories = ['uninformative',\"Casualties and damage\",\"Caution and advice\", \n",
    "        \"Informative, other\", \"Information Source\", \"Donations of money, goods or services\",\n",
    "             'People missing, found or seen']\n",
    "cm_df = pd.DataFrame(data=cm, index=categories,columns=None)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best model to predict categories for Hurricane Michael tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50043, 11)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michael = pd.read_pickle('../data/hurricane_michael.pkl')\n",
    "michael.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>geo</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>to</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-12 23:59:57+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>#HurricaneMichael #blessed #UnitedWeStand #tal...</td>\n",
       "      <td>1050898900582838272</td>\n",
       "      <td>@COTNews</td>\n",
       "      <td>https://twitter.com/joeearenas/status/10508989...</td>\n",
       "      <td>0</td>\n",
       "      <td>@COTNews has been working 24/7 to restore serv...</td>\n",
       "      <td>None</td>\n",
       "      <td>joeearenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-12 23:59:53+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1050898882526371842</td>\n",
       "      <td></td>\n",
       "      <td>https://twitter.com/LakesideBexley/status/1050...</td>\n",
       "      <td>0</td>\n",
       "      <td>In the wake of Hurricane Michael, we understan...</td>\n",
       "      <td>None</td>\n",
       "      <td>LakesideBexley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-12 23:59:52+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>#HurricaneMichael #Florida</td>\n",
       "      <td>1050898882077442048</td>\n",
       "      <td></td>\n",
       "      <td>https://twitter.com/PRAISETRIUNEGOD/status/105...</td>\n",
       "      <td>0</td>\n",
       "      <td>Maybe 17 \" #HurricaneMichael Updates: Body Fou...</td>\n",
       "      <td>None</td>\n",
       "      <td>PRAISETRIUNEGOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-12 23:59:49+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1050898865988222976</td>\n",
       "      <td></td>\n",
       "      <td>https://twitter.com/aShartee/status/1050898865...</td>\n",
       "      <td>0</td>\n",
       "      <td>In other news praying for those affected by hu...</td>\n",
       "      <td>None</td>\n",
       "      <td>aShartee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-12 23:59:43+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>#HurricaneMichael #ExcessiveForce</td>\n",
       "      <td>1050898841879236608</td>\n",
       "      <td></td>\n",
       "      <td>https://twitter.com/MindOfMo/status/1050898841...</td>\n",
       "      <td>0</td>\n",
       "      <td>iSpy 2 or 3 who'd be hard-pressed to RUN in an...</td>\n",
       "      <td>CBSNews</td>\n",
       "      <td>MindOfMo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  favorites geo  \\\n",
       "0 2018-10-12 23:59:57+00:00          4       \n",
       "1 2018-10-12 23:59:53+00:00          1       \n",
       "2 2018-10-12 23:59:52+00:00          0       \n",
       "3 2018-10-12 23:59:49+00:00          0       \n",
       "4 2018-10-12 23:59:43+00:00          0       \n",
       "\n",
       "                                            hashtags                   id  \\\n",
       "0  #HurricaneMichael #blessed #UnitedWeStand #tal...  1050898900582838272   \n",
       "1                                                     1050898882526371842   \n",
       "2                         #HurricaneMichael #Florida  1050898882077442048   \n",
       "3                                                     1050898865988222976   \n",
       "4                  #HurricaneMichael #ExcessiveForce  1050898841879236608   \n",
       "\n",
       "   mentions                                          permalink  retweets  \\\n",
       "0  @COTNews  https://twitter.com/joeearenas/status/10508989...         0   \n",
       "1            https://twitter.com/LakesideBexley/status/1050...         0   \n",
       "2            https://twitter.com/PRAISETRIUNEGOD/status/105...         0   \n",
       "3            https://twitter.com/aShartee/status/1050898865...         0   \n",
       "4            https://twitter.com/MindOfMo/status/1050898841...         0   \n",
       "\n",
       "                                                text       to         username  \n",
       "0  @COTNews has been working 24/7 to restore serv...     None       joeearenas  \n",
       "1  In the wake of Hurricane Michael, we understan...     None   LakesideBexley  \n",
       "2  Maybe 17 \" #HurricaneMichael Updates: Body Fou...     None  PRAISETRIUNEGOD  \n",
       "3  In other news praying for those affected by hu...     None         aShartee  \n",
       "4  iSpy 2 or 3 who'd be hard-pressed to RUN in an...  CBSNews         MindOfMo  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michael.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweet text\n",
    "michael['clean_text'] = clean_tweets(michael['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform out-of-event testing data with the already-fit CountVectorizer.\n",
    "michael_cvec = pd.DataFrame(cvec.transform(michael['clean_text']).todense(),\n",
    "                           columns = cvec.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael['pred'] = lr_model.predict(michael_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    28921\n",
       "2.0     8360\n",
       "1.0     4744\n",
       "4.0     4174\n",
       "5.0     2975\n",
       "3.0      843\n",
       "6.0       26\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michael.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael.to_pickle('../data/michael_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "# 0 'uninformative'\n",
    "# 1 \"Casualties and damage\"\n",
    "# 2 \"Caution and advice\", \n",
    "# 3 \"Informative, other\"\n",
    "# 4 \"Information Source\", \n",
    "# 5 \"Donations of money, goods or services\",\n",
    "# 6 'People missing, found or seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make separate files for the first 20 records in each of 4 predicted categories \n",
    "mask = michael.pred == 1\n",
    "casualties = michael[mask][0:20]\n",
    "\n",
    "mask = michael.pred == 2\n",
    "caution_advice = michael[mask][0:20]\n",
    "\n",
    "mask = michael.pred == 4\n",
    "info_source = michael[mask][0:20]\n",
    "\n",
    "mask = michael.pred == 5\n",
    "donations = michael[mask][0:20]\n",
    "\n",
    "cols = ['permalink', 'text']\n",
    "casualties = casualties[cols]\n",
    "caution_advice = caution_advice[cols]\n",
    "info_source = info_source[cols]\n",
    "donations = donations[cols]\n",
    "\n",
    "casualties.to_pickle('../data/casualties.pkl')\n",
    "caution_advice.to_pickle('../data/caution_advice.pkl')\n",
    "info_source.to_pickle('../data/info_source.pkl')\n",
    "donations.to_pickle('../data/donations.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
