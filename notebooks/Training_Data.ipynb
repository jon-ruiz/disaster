{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "### Sources: \n",
    "#### 1. Hurricanes Harvey, Irma and Maria\n",
    "Firoj Alam, Ferda Ofli, Muhammad Imran. CrisisMMD: Multimodal Twitter Datasets from Natural Disasters. To appear at the 12th International AAAI Conference on Web and Social Media (ICWSM), 2018, Stanford, California, USA. [Bibtex]\n",
    "\n",
    "#### 2. Hurricane Sandy and Joplin Tornado\n",
    "Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, and Patrick Meier. Practical Extraction of Disaster-Relevant Information from Social Media. In Proceedings of the 22nd international conference on World Wide Web companion, May 2013, Rio de Janeiro, Brazil. [Bibtex]\n",
    "\n",
    "Data downloaded from https://crisisnlp.qcri.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hurricanes Harvey, Irma and Maria\n",
    "#### Import three separate hurricane tweet archives from original tab-separated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey = pd.read_csv('../data/annotations/hurricane_harvey_final_data.tsv',delimiter='\\t')\n",
    "harvey['event'] = 'harvey'\n",
    "\n",
    "irma = pd.read_csv('../data/annotations/hurricane_irma_final_data.tsv',delimiter='\\t')\n",
    "irma['event'] = 'irma'\n",
    "\n",
    "maria = pd.read_csv('../data/annotations/hurricane_maria_final_data.tsv',delimiter='\\t')\n",
    "maria['event'] = 'maria'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the three files and examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13530, 16)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([harvey,irma,maria], axis=0)\n",
    "# this is the total number of images, not the total number of tweets\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maria     4562\n",
       "irma      4525\n",
       "harvey    4443\n",
       "Name: event, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.event.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These files have one record per tweet image, not per tweet. Remove dupicates by dropping image columns and then removing duplicates and nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns\n",
    "cols = ['tweet_id', 'text_info', 'text_human', 'tweet_text', 'event']\n",
    "train = train[cols]\n",
    "\n",
    "# drop duplicates - (due to tweets with multiple images)\n",
    "train.drop_duplicates(inplace=True)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9465, 5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tweet Category Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_relevant_information                4653\n",
       "rescue_volunteering_or_donation_effort    2635\n",
       "infrastructure_and_utility_damage          907\n",
       "not_relevant_or_cant_judge                 717\n",
       "affected_individuals                       329\n",
       "injured_or_dead_people                     159\n",
       "vehicle_damage                              50\n",
       "missing_or_found_people                     15\n",
       "Name: text_human, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this field has the categories\n",
    "train.text_human.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "informative        8748\n",
       "not_informative     717\n",
       "Name: text_info, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the not informative tweets are the one coded as \"not_relevant_or_cant_judge\" in \"text_human\"\n",
    "train.text_info.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numerical y variable coded 1 through 7\n",
    "train['y'] = train.text_human.map(\n",
    "    {\"other_relevant_information\":1,\"rescue_volunteering_or_donation_effort\":2, \n",
    "     \"infrastructure_and_utility_damage\":3, \"not_relevant_or_cant_judge\":4,\n",
    "     \"affected_individuals\":5, 'injured_or_dead_people':6, 'vehicle_damage':7,\n",
    "     'missing_or_found_people':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.491601\n",
       "2    0.278394\n",
       "3    0.095827\n",
       "4    0.075753\n",
       "5    0.034760\n",
       "6    0.016799\n",
       "7    0.005283\n",
       "8    0.001585\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.y.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('../data/train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hurricane Sandy and Joplin Tornado\n",
    "#### Read and merge tweet archives. \n",
    "##### Labeled tweets were saved in multiple files for each event, with lower-numbered files having more detailed coding about categories. We only need the first file, which gives us informative / not-informative, and the second file, which gives us the categories for the informative tweets.\n",
    "### a. Joplin Tornado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read first-level coding file for Joplin tweets\n",
    "joplin = pd.read_csv('../data/Joplin_2011_labeled_data/01_personal-informative-other/a131709.csv',\n",
    "                     index_col='_unit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Personal only                       794\n",
       "Informative (Direct or Indirect)    762\n",
       "Informative (Indirect)              469\n",
       "Informative (Direct)                265\n",
       "Other                                94\n",
       "Name: choose_one, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the top-level coding\n",
    "joplin.choose_one.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2384, 10)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2,384 coded tweets\n",
    "joplin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read second-level file\n",
    "joplin2 = pd.read_csv('../data/Joplin_2011_labeled_data/02_informative_caution-infosrc-donation-damage-other/a121571.csv',\n",
    "                  index_col='_unit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1233, 12)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joplin2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caution and advice                       436\n",
       "Information source                       280\n",
       "Donations of money, goods or services    204\n",
       "Casualties and damage                    137\n",
       "Unknown                                  130\n",
       "People missing, found or seen             46\n",
       "Name: choose_one, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the second-level coding\n",
    "joplin2.choose_one.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine first and second-level Joplin files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the uninformative tweets from the first file, since the \n",
    "# informative ones are futher coded in the second file (most of them were)\n",
    "mask = ((joplin['choose_one'] == 'Personal only') | (joplin['choose_one'] == 'Other'))\n",
    "joplin_uninformative = joplin[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 10)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joplin_uninformative.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: there are 263 more tweets that are coded as informative in the first-level file then the total number of tweets in the second-level file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1233 entries, 191082764 to 191083996\n",
      "Data columns (total 12 columns):\n",
      "_golden                  1233 non-null bool\n",
      "_unit_state              1233 non-null object\n",
      "_trusted_judgments       1233 non-null int64\n",
      "_last_judgment_at        1233 non-null object\n",
      "choose_one               1233 non-null object\n",
      "choose_one:confidence    1233 non-null float64\n",
      "choose_one_gold          62 non-null object\n",
      "id                       1233 non-null int64\n",
      "retweetcount             649 non-null float64\n",
      "screenname               1221 non-null object\n",
      "text                     1233 non-null object\n",
      "userid                   1221 non-null float64\n",
      "dtypes: bool(1), float64(3), int64(2), object(6)\n",
      "memory usage: 116.8+ KB\n"
     ]
    }
   ],
   "source": [
    "joplin2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2384 entries, 204690712 to 204693117\n",
      "Data columns (total 10 columns):\n",
      "_golden                  2384 non-null bool\n",
      "_unit_state              2384 non-null object\n",
      "_trusted_judgments       2384 non-null int64\n",
      "_last_judgment_at        2384 non-null object\n",
      "choose_one               2384 non-null object\n",
      "choose_one:confidence    2384 non-null float64\n",
      "choose_one_gold          78 non-null object\n",
      "predicted                2383 non-null object\n",
      "text_no_rt               2384 non-null object\n",
      "tweet                    2384 non-null object\n",
      "dtypes: bool(1), float64(1), int64(1), object(7)\n",
      "memory usage: 188.6+ KB\n"
     ]
    }
   ],
   "source": [
    "joplin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauls\\Anaconda3\\envs\\dsi\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# rename columns from second file\n",
    "joplin2.rename(columns={'choose_one':'category','text':'tweet'}, inplace=True)\n",
    "\n",
    "# combine the two files\n",
    "joplin_all = pd.concat([joplin_uninformative, joplin2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an event identifier that we can use when we merge the files\n",
    "joplin_all['event'] = 'joplin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2121, 16)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joplin_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2121 entries, 204690718 to 191083996\n",
      "Data columns (total 16 columns):\n",
      "_golden                  2121 non-null bool\n",
      "_last_judgment_at        2121 non-null object\n",
      "_trusted_judgments       2121 non-null int64\n",
      "_unit_state              2121 non-null object\n",
      "category                 1233 non-null object\n",
      "choose_one               888 non-null object\n",
      "choose_one:confidence    2121 non-null float64\n",
      "choose_one_gold          86 non-null object\n",
      "event                    2121 non-null object\n",
      "id                       1233 non-null float64\n",
      "predicted                887 non-null object\n",
      "retweetcount             649 non-null float64\n",
      "screenname               1221 non-null object\n",
      "text_no_rt               888 non-null object\n",
      "tweet                    2121 non-null object\n",
      "userid                   1221 non-null float64\n",
      "dtypes: bool(1), float64(4), int64(1), object(10)\n",
      "memory usage: 267.2+ KB\n"
     ]
    }
   ],
   "source": [
    "joplin_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read first file for Sandy tweets\n",
    "sandy = pd.read_csv('../data/sandy2012_labeled_data/01_personal-informative-other/a143145.csv',\n",
    "                  index_col='_unit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,000 coded Sandy tweets\n",
    "sandy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 221934923 to 221941939\n",
      "Data columns (total 11 columns):\n",
      "_golden                  1000 non-null bool\n",
      "_unit_state              1000 non-null object\n",
      "_trusted_judgments       1000 non-null int64\n",
      "_last_judgment_at        1000 non-null object\n",
      "choose_one               1000 non-null object\n",
      "choose_one:confidence    1000 non-null float64\n",
      "choose_one_gold          51 non-null object\n",
      "nil                      1 non-null object\n",
      "text_no_rt               1000 non-null object\n",
      "tweet                    1000 non-null object\n",
      "user                     1000 non-null object\n",
      "dtypes: bool(1), float64(1), int64(1), object(8)\n",
      "memory usage: 86.9+ KB\n"
     ]
    }
   ],
   "source": [
    "sandy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Informative (Indirect)              386\n",
       "Personal Only                       296\n",
       "Other                               161\n",
       "Informative (Direct or Indirect)     79\n",
       "Informative (Direct)                 78\n",
       "Name: choose_one, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy.choose_one.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read second-level Sandy file\n",
    "sandy2 = pd.read_csv('../data/sandy2012_labeled_data/02_informative_caution-infosrc-donation-damage-other/a144267.csv',\n",
    "                  index_col='_unit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Casualties and damage                    170\n",
       "Caution and advice                       144\n",
       "Unknown                                  125\n",
       "Information Source                        72\n",
       "Donations of money, goods or services     32\n",
       "Name: choose_one, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy2.choose_one.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 11)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 543 entries, 223607030 to 223607572\n",
      "Data columns (total 11 columns):\n",
      "_golden                  543 non-null bool\n",
      "_unit_state              543 non-null object\n",
      "_trusted_judgments       543 non-null int64\n",
      "_last_judgment_at        543 non-null object\n",
      "choose_one               543 non-null object\n",
      "choose_one:confidence    543 non-null float64\n",
      "choose_one_gold          41 non-null object\n",
      "text_no_rt               543 non-null object\n",
      "tweet                    543 non-null object\n",
      "type                     543 non-null object\n",
      "user                     543 non-null object\n",
      "dtypes: bool(1), float64(1), int64(1), object(8)\n",
      "memory usage: 47.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sandy2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the two Sandy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((sandy['choose_one'] == 'Personal Only') | (sandy['choose_one'] == 'Other'))\n",
    "\n",
    "sandy_uninformative = sandy[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 11)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_uninformative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of 2nd level Sandy file\n",
    "sandy2.rename(columns={'choose_one':'category'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauls\\Anaconda3\\envs\\dsi\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# merge Joplin and Sandy first-level files\n",
    "sandy_all = pd.concat([sandy_uninformative,sandy2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an event identifier that we can use when we merge the files\n",
    "sandy_all['event'] = 'sandy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 221934923 to 223607572\n",
      "Data columns (total 14 columns):\n",
      "_golden                  1000 non-null bool\n",
      "_last_judgment_at        1000 non-null object\n",
      "_trusted_judgments       1000 non-null int64\n",
      "_unit_state              1000 non-null object\n",
      "category                 543 non-null object\n",
      "choose_one               457 non-null object\n",
      "choose_one:confidence    1000 non-null float64\n",
      "choose_one_gold          65 non-null object\n",
      "nil                      1 non-null object\n",
      "text_no_rt               1000 non-null object\n",
      "tweet                    1000 non-null object\n",
      "type                     543 non-null object\n",
      "user                     1000 non-null object\n",
      "event                    1000 non-null object\n",
      "dtypes: bool(1), float64(1), int64(1), object(11)\n",
      "memory usage: 110.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sandy_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Sandy-only file\n",
    "train_sandy = sandy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y variable\n",
    "train_sandy['y'] = train3['category'].map(\n",
    "    {\"Casualties and damage\":1,\"Caution and advice\":2, \n",
    "     \"Unknown\":3, \"Information Source\":4,\"Information source\":4,\"Donations of money, goods or services\":5,\n",
    "    'People missing, found or seen':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sandy['y'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sandy.to_pickle('../data/train_sandy.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Joplin and Sandy data into single df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauls\\Anaconda3\\envs\\dsi\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train3 = pd.concat([joplin_all,sandy_all], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3121, 19)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3121 entries, 204690718 to 223607572\n",
      "Data columns (total 19 columns):\n",
      "_golden                  3121 non-null bool\n",
      "_last_judgment_at        3121 non-null object\n",
      "_trusted_judgments       3121 non-null int64\n",
      "_unit_state              3121 non-null object\n",
      "category                 1776 non-null object\n",
      "choose_one               1345 non-null object\n",
      "choose_one:confidence    3121 non-null float64\n",
      "choose_one_gold          151 non-null object\n",
      "event                    1000 non-null object\n",
      "id                       1233 non-null float64\n",
      "nil                      1 non-null object\n",
      "predicted                887 non-null object\n",
      "retweetcount             649 non-null float64\n",
      "screenname               1221 non-null object\n",
      "text_no_rt               1888 non-null object\n",
      "tweet                    3121 non-null object\n",
      "type                     543 non-null object\n",
      "user                     1000 non-null object\n",
      "userid                   1221 non-null float64\n",
      "dtypes: bool(1), float64(4), int64(1), object(13)\n",
      "memory usage: 466.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caution and advice                       580\n",
       "Casualties and damage                    307\n",
       "Information source                       280\n",
       "Unknown                                  255\n",
       "Donations of money, goods or services    236\n",
       "Information Source                        72\n",
       "People missing, found or seen             46\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3['y'] = train3['category'].map(\n",
    "    {\"Casualties and damage\":1,\"Caution and advice\":2, \n",
    "     \"Unknown\":3, \"Information Source\":4,\"Information source\":4,\"Donations of money, goods or services\":5,\n",
    "    'People missing, found or seen':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3['y'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1345\n",
       "2.0     580\n",
       "4.0     352\n",
       "1.0     307\n",
       "3.0     255\n",
       "5.0     236\n",
       "6.0      46\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.to_pickle('../data/train3.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
