{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (preliminary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle(\"../data/train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating relevant columns\n",
    "tweets.drop(columns=[\"tweet_id\", \"text_info_conf\", \"text_human_conf\", \"image_id\", \"image_info\", \"image_info_conf\", \"image_human\", \"image_human_conf\", \"image_damage\", \"image_damage_conf\", \"image_url\", \"image_path\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making text_info binary\n",
    "\n",
    "#drop rows where text_info == \"dont_know_or_cant_judge\"\n",
    "tweets = tweets[tweets.text_info != \"dont_know_or_cant_judge\"]\n",
    "\n",
    "#map new values\n",
    "tweets[\"info_binary\"] = tweets.text_info.map({\"informative\":1,\"not_informative\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.720242\n",
       "0    0.279758\n",
       "Name: info_binary, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.info_binary.value_counts(1) #baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tweets lowercase\n",
    "lower_tweets = []\n",
    "for tweet in tweets.tweet_text:\n",
    "    lower_tweets.append(tweet.lower())\n",
    "\n",
    "lower_tweets = pd.DataFrame(lower_tweets)\n",
    "\n",
    "lower_tweets.rename(columns={0:\"tweet\"}, inplace=True)\n",
    "\n",
    "tweets.tweet_text = lower_tweets.tweet\n",
    "\n",
    "#truncate elongations (NO CODE FOR NOW)\n",
    "\n",
    "#spell out numbers (NO CODE FOR NOW)\n",
    "\n",
    "#replace all usernames with 'USERID'\n",
    "tweets.tweet_text = tweets.tweet_text.replace(r'@\\S+', 'USERID', regex=True)\n",
    "\n",
    "#replace all URLs with HTTP\n",
    "tweets.tweet_text = tweets.tweet_text.replace(r'http\\S+', 'HTTP', regex=True).replace(r'www\\S+', 'HTTP', regex=True)\n",
    "\n",
    "#remove \"RT\" string\n",
    "tweets.tweet_text = tweets.tweet_text.map(lambda x: x.lstrip('rt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (preliminary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Name variables \n",
    "\n",
    "X = tweets[[\"tweet_text\"]]\n",
    "y = tweets[\"info_binary\"]\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Model: CountVectorizer and Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer \n",
    "\n",
    "cvec = CountVectorizer(stop_words=\"english\")\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['tweet_text']).todense(), columns = cvec.get_feature_names())\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['tweet_text']).todense(), columns = cvec.get_feature_names())\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(X_train_cvec, y_train)\n",
    "predictions = lr.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67635468, 0.67175949, 0.66387383, 0.67258383, 0.6622288 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train_cvec, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978115141955836"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6658781785925488"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
