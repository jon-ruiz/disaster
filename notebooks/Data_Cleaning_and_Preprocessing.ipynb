{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (preliminary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle(\"../data/train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating relevant columns\n",
    "tweets.drop(columns=[\"tweet_id\", \"text_info_conf\", \"text_human_conf\", \"image_id\", \"image_info\", \"image_info_conf\", \"image_human\", \"image_human_conf\", \"image_damage\", \"image_damage_conf\", \"image_url\", \"image_path\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making text_info binary\n",
    "\n",
    "#map new values\n",
    "tweets[\"info_binary\"] = tweets.text_info.map({\"informative\":1,\"not_informative\":0, \"dont_know_or_cant_judge\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9742\n",
       "0    3788\n",
       "Name: info_binary, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.info_binary.value_counts() #baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tweets lowercase\n",
    "lower_tweets = []\n",
    "for tweet in tweets.tweet_text:\n",
    "    lower_tweets.append(tweet.lower())\n",
    "\n",
    "lower_tweets = pd.DataFrame(lower_tweets)\n",
    "\n",
    "lower_tweets.rename(columns={0:\"tweet\"}, inplace=True)\n",
    "\n",
    "tweets.tweet_text = lower_tweets.tweet\n",
    "\n",
    "#truncate elongations (NO CODE FOR NOW)\n",
    "#>>> import re\n",
    "#>>> re.sub(r'(.)\\1+', r'\\1\\1', \"haaaaapppppyyy\")  #https://stackoverflow.com/questions/10072744/remove-repeating-characters-from-words\n",
    "#spell out numbers (NO CODE FOR NOW)\n",
    "\n",
    "#replace all usernames with 'USERID'\n",
    "tweets.tweet_text = tweets.tweet_text.replace(r'@\\S+', 'USERID', regex=True)\n",
    "\n",
    "userid_tweets = []\n",
    "for tweet in tweets.tweet_text:\n",
    "    userid_tweets.append(tweet.replace('USERID', ''))\n",
    "\n",
    "userid_tweets = pd.DataFrame(lower_tweets)\n",
    "\n",
    "userid_tweets.rename(columns={0:\"tweet\"}, inplace=True)\n",
    "tweets.tweet_text = lower_tweets.tweet\n",
    "\n",
    "\n",
    "#replace all URLs with HTTP\n",
    "tweets.tweet_text = tweets.tweet_text.replace(r'http\\S+', 'HTTP', regex=True).replace(r'www\\S+', 'HTTP', regex=True)\n",
    "\n",
    "http_tweets = []\n",
    "\n",
    "for tweet in tweets.tweet_text:\n",
    "    http_tweets.append(tweet.replace('HTTP', ''))\n",
    "\n",
    "http_tweets = pd.DataFrame(http_tweets)\n",
    "\n",
    "http_tweets.rename(columns={0:\"tweet\"}, inplace=True)\n",
    "tweets.tweet_text = http_tweets.tweet\n",
    "\n",
    "#remove \"RT\" string\n",
    "tweets.tweet_text = tweets.tweet_text.map(lambda x: x.lstrip('rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13526, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates(subset=[\"tweet_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_pickle(\"../tweets_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.75675\n",
       "0    0.24325\n",
       "Name: info_binary, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.info_binary.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (preliminary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Name variables \n",
    "\n",
    "X = tweets[[\"tweet_text\"]]\n",
    "y = tweets[\"info_binary\"]\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Model: CountVectorizer and Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer \n",
    "tknzr = TweetTokenizer()\n",
    "cvec = CountVectorizer(stop_words=\"english\", tokenizer=tknzr.tokenize)\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train['tweet_text']).todense(), columns = cvec.get_feature_names())\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test['tweet_text']).todense(), columns = cvec.get_feature_names())\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(X_train_cvec, y_train)\n",
    "predictions = lr.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109999999999999"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train_cvec, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
