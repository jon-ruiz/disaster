{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Disaster Dashboards\n",
    "## Leveraging News and Media for Situational Awareness (Problem #2)\n",
    "---\n",
    "\n",
    "### Team\n",
    " - Jonathan Ruiz\n",
    " - Paul Schimek\n",
    " - Michelle Cheung\n",
    "\n",
    "### Project Statement\n",
    "---\n",
    "During a major disaster, it is essential to provide the public and responders with relevant local news updates in order to gain situational awareness during the event. During a disaster, news updates are coming from tens to hundreds of different sources, all in different formats, available from different websites, news channels etc., and it is often difficult to find what would be most helpful amid the chaos of other non-disaster related news and media. There is currently no forum for rounding up and archiving relevant news for a live disaster event. This project will leverage news feeds relevant to specific disasters, gathered from multiple sources, to create a website that presents these live feeds in one dashboard.\n",
    "\n",
    "### Objective\n",
    "---\n",
    "Social media provides valuable real-time awareness to first responders and relief workers by providing information on localized emergencies during a disaster. However, informative signals are often clouded with irrelevant noise.\n",
    "\n",
    "This goal of this project is to find a means of separating out informative from noninformative media in order to help filter and triage where actionable help is needed. Numerous classification models were used to find and compare the most effective model.\n",
    "\n",
    "### Procedure\n",
    "---\n",
    "\n",
    "The media used to train classification models were human-labeled tweets sourced from two previous studies on disaster-related social media. Approximately 13,000 tweets were retrieved from \"CrisisMMD: Multimodal Twitter Datasets from Natural Disasters<sup>1</sup>, which included tweets from Hurricane Irma (tweets dated circa Sept. 2017), Hurricane Harvey (tweets dated circa Aug. to Sept. 2017), and Hurricane Maria (tweets dated circa Sept. to Nov. 2017). These tweets were labeled as informative or not-informative based on whether a given tweet or image determined information for humanitarian aid purposes. An additional 3,000 tweets were retrieved from \"Practical Extraction of Disaster-Relevant Information from Social Media\"<sup>2</sup>, which included tweets from the Joplin Tornado (tweets dated circa May 2011) and Hurrican Sandy (tweets dated circa Oct. 2012). These tweets were labeled as either Personal (if a message was only of interest to its author and her immediate circle of family/friends and does not convey anything useful), Informative (if the message was of interest to other people beyond the authorâ€™s immediate circle), or Other (if the message was not related to the disaster). An approximate total of xx,000 tweets were used collectively to train a classifification model.\n",
    "\n",
    "Test data includes tweets retrieved related to Hurricane Michael (tweets dated circa Oct. 2018) and were retrieved through the Python library \"GetOldTweets3.\" These tweets were not labeled.\n",
    "\n",
    "Algorithms used were Logistic Regression, Naive Bayes, Random Forest, \n",
    "\n",
    "The home page will include a list of live severe weather alerts and recent FEMA disaster declarations on the national level. Severe weather alerts will be shown by \"Location\" and \"Type\" of warning. Recent disaster declarations will be shown by type, name, date, and location. For each servere weather alert and recent disaster declatation, the user will be hyperlinked to a disaster specific dashboard with a description of the event, FEMA safety instructions, relevant news items, and relevant tweets. News items and relevant tweets will be sourced from NewsAPI, and the official Twitter API (and Twitterscapper for historical tweets), respectively. The home page and hyperlinked dashboards will be built using Flask, a micro web development platform written in Python.\n",
    "\n",
    "### Findings\n",
    "---\n",
    "\n",
    "1. Classification between informative and not-informative yielded different distrubtion of informative tweets than classification among ---.\n",
    "2. Word2Vec did\n",
    "\n",
    "### Conclusions\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Project Deliverables\n",
    "---\n",
    "\n",
    "| File | Description |\n",
    "| --- | --- |\n",
    "| **model notebook** | *Project fails to meet the outlined expectations; many major issues exist.* |\n",
    "| **hurricane michael tweets pkl** | *Project close to meeting expectations; many minor issues or a few major issues.* |\n",
    "| **train tweets set pkl** | *Project meets expectations; few (and relatively minor) mistakes.* |\n",
    "| **this readme file/report** | *Project demonstrates a thorough understanding of all of the considerations outlined.* |\n",
    "| **code for website** | *Project demonstrates a thorough understanding of all of the considerations outlined.* |\n",
    "\n",
    "1. Slideshow\n",
    "2. Webscraper from at least 3 sources\n",
    "3. Open source code for disaster-specific webpage\n",
    "4. Short written description of project.\n",
    "5. Classification models for classifying type of disaster and whether disaster is live or recent\n",
    "\n",
    "### Data Sources\n",
    "---\n",
    "1. CrisisMMD: Multimodal Twitter Datasets from Natural Disasters: Firoj Alam, Ferda Ofli, Muhammad Imran\n",
    "Qatar Computing Research Institute, HBKU, Doha, Qatar\n",
    "2. Practical Extraction of Disaster-Relevant Information from\n",
    "Social Media: Muhammad Imran (University of Trento), Shady Elbassuoni (American University of Beirut), Carlos Castillo (Qatar Computing Research Institute), Fernando Diaz (Microsoft Research), Patrick Meier (Qatar Computing Research Institute)\n",
    "3. News API\n",
    "4. Twitter API\n",
    "5. GetOldTweets3  https://pypi.org/project/GetOldTweets3/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
